{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка кровяного давления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача состоит в том чтобы оценить систолическое (SBP) и диастолическое (DBP) кровяное давление для конкретного человека используя фотоплетизмограмму (PPG) и электрокардиограмму (ECG). Для каждого человека открыты несколько «калибровочных» измерений, то есть примерно 20% данных для каждого человека содержат запись о SBP и DBP наряду с соответствующими записями PPG и ECG.\n",
    "\n",
    "Данные сигналов PPG и ECG записаны в файлы вида: subjXXlogYYYY.csv, где XX есть идентификационный номер человека, а YYYY — номер записи. Первая строка файла содержит значения SBP и DBP для калибровочных измерений и нули для остальных, а последующие строки содержат семплы PPG и ECG сигналы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '../data/data_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = [f for f in os.listdir(work_dir) if os.path.isfile(work_dir+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_list) # общее количество файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на структуру файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(work_dir + files_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 2 columns):\n",
      "126    15000 non-null int64\n",
      "79     15000 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBP = 100, DBP = 67, следующие 15000 строк содержат PPG и ECG сигналы  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = list(set([int(fl.split('log')[0].split('subj')[1]) for fl in files_list])) # id участников эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 9, 11, 14, 16, 18, 21, 22, 26, 27, 30]\n"
     ]
    }
   ],
   "source": [
    "print(subjs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика качества по условиям задачи определяется как взвешенная сумма корней среднеквадратичных ошибок (RMSE), где ошибка определения DBP имеет в 2 раза больший вес, чем ошибка SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(sbp, sbpt, dbp, dbpt):\n",
    "    s, d = 0, 0\n",
    "    n = len(dbp)\n",
    "    for i in range(n):\n",
    "        s += (int(round(sbp[i])) - sbpt[i])**2\n",
    "        d += (int(round(dbp[i])) - dbpt[i])**2\n",
    "    return s, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из подходов к выделению признаков из сигналов PPG и ECG состоит в том, чтобы использовать коэффициенты БПФ. Для ускорения работы будем записывать в файл только первые 1000 коэффициентов. Так как измерения PPG и ECG независимы, можно использовать только один вид сигнала, в данном случае ECG. Из условий задачи следует, что электроды ECG могут быть наложены уже после начала записи. Поэтому несколько первых записей отброшены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fft(subj_files):\n",
    "    subj_train_files, subj_test_files = [], []\n",
    "    for sf in subj_files:\n",
    "        data = pd.read_csv(work_dir + sf)\n",
    "        if int(data.columns[0]):\n",
    "            subj_train_files.append(sf)\n",
    "        else:\n",
    "            subj_test_files.append(sf)\n",
    "\n",
    "        X = data[data.columns[1]].iloc[10:]\n",
    "        fft_feat = abs(scipy.fft(X)[:1000])\n",
    "        base_fn, ext = os.path.splitext(sf)\n",
    "        data_fn = work_dir + 'fft/' + base_fn + '.fft'\n",
    "        scipy.save(data_fn, fft_feat)\n",
    "    return subj_train_files, subj_test_files\n",
    "\n",
    "def read_fft(files):\n",
    "    X, y0, y1 = [],[],[]\n",
    "    for tf in files:\n",
    "        data = pd.read_csv(work_dir + tf)\n",
    "        y0.append(round(float(data.columns[0])))\n",
    "        y1.append(round(float(data.columns[1])))\n",
    "        base_fn, ext = os.path.splitext(tf)\n",
    "        data_fn = work_dir + 'fft/' + base_fn + '.fft.npy'\n",
    "        fft_feat = scipy.load(data_fn)\n",
    "        X.append(fft_feat[:1000])\n",
    "    return np.array(X), np.array(y0), np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "models = [linear_model.BayesianRidge(), LinearRegression(), RandomForestRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "3778.112470053079\n",
      " \n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "4812.513151152262\n",
      " \n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "2317.0599427451702\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    loss_s, loss_d = 0, 0\n",
    "\n",
    "    for i in subjs:\n",
    "        subj_files = [f for f in files_list if f.startswith('subj' + str(i) + 'log')]\n",
    "        subj_train, subj_test = write_fft(subj_files)\n",
    "        subj_train = subj_files[:int(len(subj_files)*0.2)]\n",
    "        subj_test = subj_files[int(len(subj_files)*0.2):]\n",
    "        X_train, y0_train, y1_train = read_fft(subj_train)\n",
    "        X_test, y0_real, y1_real = read_fft(subj_test)\n",
    "        model.fit(X_train, y0_train)\n",
    "        y0_test = model.predict(X_test)\n",
    "        model.fit(X_train, y1_train)\n",
    "        y1_test = model.predict(X_test)\n",
    "        s, d  = loss_f(y0_test, y0_real, y1_test, y1_real)\n",
    "        loss_s += s\n",
    "        loss_d += d \n",
    "    \n",
    "    lf = len(files_list)\n",
    "    print(model)    \n",
    "    print(100. * (loss_s / float(lf))**0.5 + 200. * (loss_d / float(lf))**0.5)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из трех моделей лучше всего сработал RandomForest. Была идея попробовать также классификаторы (давление одного человека колеблется в небольшом диапазоне), но времени не хватило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
